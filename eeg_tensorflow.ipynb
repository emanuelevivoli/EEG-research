{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification - Tensorflow\n",
    "updated: Sep. 01, 2018\n",
    "\n",
    "Data: https://www.physionet.org/pn4/eegmmidb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Downloads\n",
    "\n",
    "### Warning: Executing these blocks will automatically create directories and download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0702 16:00:58.624246 4726728128 deprecation_wrapper.py:119] From /anaconda3/envs/eeg-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0702 16:00:58.625966 4726728128 deprecation_wrapper.py:119] From /anaconda3/envs/eeg-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0702 16:00:58.627233 4726728128 deprecation_wrapper.py:119] From /anaconda3/envs/eeg-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0702 16:00:58.646740 4726728128 deprecation_wrapper.py:119] From /anaconda3/envs/eeg-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow Style Guide\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# System\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import urllib\n",
    "\n",
    "# Modeling & Preprocessing\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense, Dropout, LSTM, Input, TimeDistributed\n",
    "from keras import initializers, Model, optimizers, callbacks\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback, TensorBoard\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "# Essential Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil, floor\n",
    "\n",
    "# Get Paths\n",
    "from glob import glob\n",
    "\n",
    "# EEG package\n",
    "from mne import pick_types, events_from_annotations\n",
    "from mne.io import read_raw_edf\n",
    "\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to take the dataset from physionet web site\n",
    "CONTEXT = 'pn4/'\n",
    "MATERIAL = 'eegmmidb/'\n",
    "URL = 'https://www.physionet.org/' + CONTEXT + MATERIAL\n",
    "\n",
    "# Change this directory according to your setting\n",
    "USERDIR = './py/data/'\n",
    "\n",
    "page = requests.get(URL).text\n",
    "FOLDERS = sorted(list(set(re.findall(r'S[0-9]+', page))))\n",
    "\n",
    "URLS = [URL+x+'/' for x in FOLDERS]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Warning: Executing this block will create folders\n",
    "for folder in FOLDERS:\n",
    "    pathlib.Path(USERDIR +'/'+ folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Warning: Executing this block will start downloading data\n",
    "for i, folder in enumerate(FOLDERS):\n",
    "    page = requests.get(URLS[i]).text\n",
    "    subs = list(set(re.findall(r'S[0-9]+R[0-9]+', page)))\n",
    "    \n",
    "    print('Working on {}, {:.1%} completed'.format(folder, (i+1)/len(FOLDERS)))\n",
    "    for sub in subs:\n",
    "        urllib.request.urlretrieve(URLS[i]+sub+'.edf', os.path.join(USERDIR, folder, sub+'.edf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: \n",
    "\n",
    "- two one-minute baseline runs (one with eyes open, one with eyes closed)\n",
    "- three two-minute runs of each of the four following tasks:\n",
    "    - 1:\n",
    "        - A target appears on either the left or the right side of the screen. \n",
    "        - The subject opens and closes the corresponding fist until the target disappears. \n",
    "        - Then the subject relaxes.\n",
    "    - 2:\n",
    "        - A target appears on either the left or the right side of the screen. \n",
    "        - The subject imagines opening and closing the corresponding fist until the target disappears. \n",
    "        - Then the subject relaxes.\n",
    "    - 3:\n",
    "        - A target appears on either the top or the bottom of the screen. \n",
    "        - The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. \n",
    "        - Then the subject relaxes.\n",
    "    - 4:\n",
    "        - A target appears on either the top or the bottom of the screen. \n",
    "        - The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. \n",
    "        - Then the subject relaxes.\n",
    "\n",
    "The data are provided here in EDF+ format (containing 64 EEG signals, each sampled at 160 samples per second, and an annotation channel). \n",
    "For use with PhysioToolkit software, rdedfann generated a separate PhysioBank-compatible annotation file (with the suffix .event) for each recording. \n",
    "The .event files and the annotation channels in the corresponding .edf files contain identical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary tasks\n",
    "\n",
    "Remembering that:\n",
    "\n",
    "    - Task 1 (open and close left or right fist)\n",
    "    - Task 2 (imagine opening and closing left or right fist)\n",
    "    - Task 3 (open and close both fists or both feet)\n",
    "    - Task 4 (imagine opening and closing both fists or both feet)\n",
    "\n",
    "we will referred to 'Task *' with the meneaning above. \n",
    "\n",
    "In summary, the experimental runs were:\n",
    "\n",
    "1.  Baseline, eyes open\n",
    "2.  Baseline, eyes closed\n",
    "3.  Task 1 \n",
    "4.  Task -2 \n",
    "5.  Task --3 \n",
    "6.  Task ---4 \n",
    "7.  Task 1\n",
    "8.  Task -2\n",
    "9.  Task --3\n",
    "10. Task ---4\n",
    "11. Task 1\n",
    "12. Task -2\n",
    "13. Task --3\n",
    "14. Task ---4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation\n",
    "\n",
    "Each annotation includes one of three codes (T0, T1, or T2):\n",
    "\n",
    "- T0 corresponds to rest\n",
    "- T1 corresponds to onset of motion (real or imagined) of\n",
    "    - the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "    - both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "- T2 corresponds to onset of motion (real or imagined) of\n",
    "    - the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "    - both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "    \n",
    "In the BCI2000-format versions of these files, which may be available from the contributors of this data set, these annotations are encoded as values of 0, 1, or 2 in the TargetCode state variable.\n",
    "\n",
    "{'T0':0, 'T1':1, 'T2':2}\n",
    "\n",
    "In our experiments we will see only :\n",
    "\n",
    "- run_type_0:\n",
    "    - append_X\n",
    "- run_type_1\n",
    "    - append_X_y\n",
    "- run_type_2\n",
    "    - append_X_y\n",
    "    \n",
    "and the coding is: \n",
    "\n",
    "- T0 corresponds to rest \n",
    "    - (2)\n",
    "- T1 (real or imagined)\n",
    "    - (4,  8, 12) the left fist \n",
    "    - (6, 10, 14) both fists \n",
    "- T2 (real or imagined)\n",
    "    - (4,  8, 12) the right fist \n",
    "    - (6, 10, 14) both feet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Import\n",
    "\n",
    "I will use a EEG data handling package named MNE (https://martinos.org/mne/stable/index.html) to import raw data and annotation for events from edf files. This package also provides essential signal analysis features, e.g. band-pass filtering. The raw data were filtered using 1Hz of high-pass filter.\n",
    "\n",
    "In this research, there are 5 classes for the data, imagined motion of:\n",
    "    - right fist, \n",
    "    - left fist, \n",
    "    - both fists, \n",
    "    - both feet,\n",
    "    - rest with eyes closed.\n",
    "\n",
    "A data (S089) from one of the 109 subjects was excluded as the record was severely corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "PATH = './py/data/'\n",
    "SUBS = glob(PATH + 'S[0-9]*')\n",
    "FNAMES = sorted([x[-4:] for x in SUBS])\n",
    "\n",
    "REMOVE = ['S088', 'S089', 'S092', 'S100']\n",
    "\n",
    "# Remove subject 'S089' with damaged data and 'S088', 'S092', 'S100' with 128Hz sampling rate (we want 160Hz)\n",
    "FNAMES = [ x for x in FNAMES if x not in REMOVE] \n",
    "\n",
    "emb = {'T0': 1, 'T1': 2, 'T2': 3}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_data(subj_num=FNAMES, epoch_sec=0.0625):\n",
    "    \"\"\" Import from edf files data and targets in the shape of 3D tensor\n",
    "    \n",
    "        Output shape: (Trial*Channel*TimeFrames)\n",
    "        \n",
    "        Some edf+ files recorded at low sampling rate, 128Hz, are excluded. \n",
    "        Majority was sampled at 160Hz.\n",
    "        \n",
    "        epoch_sec: time interval for one segment of mashes (0.0625 is 1/16 as a fraction)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Event codes mean different actions for two groups of runs\n",
    "    run_type_0 = '01'.split(',')\n",
    "    run_type_1 = '03,07,11'.split(',')\n",
    "    run_type_2 = '05,09,13'.split(',')\n",
    "    \n",
    "    # Initiate X, y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # To compute the completion rate\n",
    "    count = len(subj_num)\n",
    "    \n",
    "    # fixed numbers\n",
    "    nChan = 64 \n",
    "    sfreq = 160\n",
    "    sliding = epoch_sec/2 \n",
    "    timeFromQue = 0.5\n",
    "\n",
    "    # Sub-function to assign X and X, y\n",
    "    def append_X(n_segments, data, event=[]):\n",
    "        # Data should be changed\n",
    "        '''This function generate a tensor for X and append it to the existing X'''\n",
    "        \n",
    "        if len(event):\n",
    "            event_start = ceil(event[0] * sfreq)\n",
    "        else:\n",
    "            event_start = 0\n",
    "    \n",
    "        def window(n):\n",
    "            windowStart = int(timeFromQue*sfreq) + int(sfreq*sliding*n) + event_start\n",
    "            windowEnd = int(timeFromQue*sfreq) + int(sfreq*sliding*(n+2)) + event_start\n",
    "            \n",
    "            while (windowEnd - windowStart) != 10:\n",
    "                windowEnd += int(sfreq*epoch_sec) - (windowEnd - windowStart)\n",
    "                \n",
    "            return [windowStart, windowEnd]\n",
    "        \n",
    "        # new_x = [ data[:, window(n)[0]: window(n)[1]] for n in range(n_segments)\\\n",
    "        #        if data[:, window(n)[0]:window(n)[1]].shape==(nChan, int(sfreq*epoch_sec))]\n",
    "        \n",
    "        new_x = []\n",
    "        for n in range(n_segments):\n",
    "            print('data[:, ',window(n)[0],':',window(n)[1],'].shape = ', data[:, window(n)[0]:window(n)[1]].shape, '(',nChan,',',int(sfreq*epoch_sec),')')\n",
    "            \n",
    "            if data[:, window(n)[0]:window(n)[1]].shape==(nChan, int(sfreq*epoch_sec)):\n",
    "                new_x.append(data[:, window(n)[0]: window(n)[1]])\n",
    "                 \n",
    "        return new_x\n",
    "    \n",
    "    def append_X_Y(run_type, event, old_x, old_y, data):\n",
    "        '''This function seperate the type of events \n",
    "        (refer to the data descriptitons for the list of the types)\n",
    "        Then assign X and Y according to the event types'''\n",
    "        # Number of sliding windows\n",
    "        # n_segments = int(event[1]/epoch_sec)\n",
    "        print('data', data.shape[1])\n",
    "        n_segments = int((data.shape[1]/(epoch_sec*sfreq)))\n",
    "        print('n_segment', n_segments)\n",
    "        \n",
    "        \n",
    "        # Rest excluded\n",
    "        if event[2] == emb['T0']:\n",
    "            return old_x, old_y\n",
    "        \n",
    "        # y assignment\n",
    "        if run_type == 1:\n",
    "            temp_y = [1] if event[2] == 'T1' else [2]\n",
    "        \n",
    "        elif run_type == 2:\n",
    "            temp_y = [3] if event[2] == 'T1' else [4]\n",
    "                \n",
    "        new_x = append_X(n_segments, data, event)\n",
    "        new_y = old_y + temp_y*len(new_x)\n",
    "        \n",
    "        return old_x + new_x, new_y\n",
    "    \n",
    "    # Iterate over subj_num: S001, S002, S003, ...\n",
    "    for i, subj in enumerate(subj_num):\n",
    "        \n",
    "        # print('X shape', np.array(X).shape)\n",
    "        print('subj:', subj, '| y.shape', np.array(y).shape ,'| X.shape', np.array(X).shape)\n",
    "        \n",
    "        # Return completion rate\n",
    "        # if i%((len(subj_num)//10)+1) == 0:\n",
    "            # print('working on {}, {:.0%} completed'.format(subj, i/count))\n",
    "\n",
    "        # Get file names\n",
    "        fnames = glob(os.path.join(PATH, subj, subj+'R*.edf'))\n",
    "        # Hold only the files that have an even number\n",
    "        fnames = sorted([name for name in fnames if name[-6:-4] in run_type_0+run_type_1+run_type_2])\n",
    "\n",
    "        # for each of ['02', '04', '06', '08', '12', '14']\n",
    "        for i, fname in enumerate(fnames):\n",
    "            \n",
    "            # Import data into MNE raw object\n",
    "            raw = read_raw_edf(fname, preload=True, verbose=False)\n",
    "            \n",
    "            picks = pick_types(raw.info, eeg=True)\n",
    "            print('n_times', raw.n_times)\n",
    "            \n",
    "            if raw.info['sfreq'] != 160:\n",
    "                print('{} is sampled at 128Hz so will be excluded.'.format(subj))\n",
    "                break\n",
    "            \n",
    "            # High-pass filtering\n",
    "            raw.filter(l_freq=1, h_freq=None, picks=picks)\n",
    "            \n",
    "            # Get annotation\n",
    "            try:\n",
    "                events = events_from_annotations(raw, verbose=False)\n",
    "                # print(events[1])\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            # Get data\n",
    "            data = raw.get_data(picks=picks)\n",
    "            print('event.shape', np.array(events[0]).shape, '| data.shape', data.shape)\n",
    "            \n",
    "            # Number of this run\n",
    "            which_run = fname[-6:-4]\n",
    "            \n",
    "            \"\"\" Assignment Starts \"\"\" \n",
    "            # run 1 - baseline (eye closed)\n",
    "            if which_run in run_type_0:\n",
    "\n",
    "                # Number of sliding windows\n",
    "                # 976 <- 9760 / (160 * 1/16)\n",
    "                n_segments = int((raw.n_times/(epoch_sec*sfreq)))\n",
    "\n",
    "                # Append 0`s based on number of windows\n",
    "                new_X = append_X(n_segments, data)\n",
    "                X += new_X\n",
    "                y.extend([0] * len(new_X))\n",
    "                # print('0 shape', np.array(X).shape)\n",
    "                print(events[0])   \n",
    "                    \n",
    "            # run 4,8,12 - imagine opening and closing left or right fist    \n",
    "            elif which_run in run_type_1:\n",
    "                # print('run type 1')\n",
    "                for i, event in enumerate(events[0]):\n",
    "                    X, y = append_X_Y(run_type=1, event=event, old_x=X, old_y=y, data=data)\n",
    "                    # print('1 shape', np.array(X).shape)\n",
    "                    print(event)   \n",
    "                        \n",
    "            # run 6,10,14 - imagine opening and closing both fists or both feet\n",
    "            elif which_run in run_type_2:\n",
    "                # print('run type 2')\n",
    "                for i, event in enumerate(events[0]):         \n",
    "                    X, y = append_X_Y(run_type=2, event=event, old_x=X, old_y=y, data=data)\n",
    "                    # print('2 shape', np.array(X).shape)\n",
    "                    \n",
    "                    print(event)    \n",
    "            \n",
    "        # print('X shape', np.array(X).shape)\n",
    "        print('subj:', subj, '| y.shape', np.array(y).shape ,'| X.shape', np.array(X).shape)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "    print(np.array(X).shape)\n",
    "    # print(X)\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subj_num=FNAMES, epoch_sec=0.0625):\n",
    "    \"\"\" Import from edf files data and targets in the shape of 3D tensor\n",
    "    \n",
    "        Output shape: (Trial*Channel*TimeFrames)\n",
    "        \n",
    "        Some edf+ files recorded at low sampling rate, 128Hz, are excluded. \n",
    "        Majority was sampled at 160Hz.\n",
    "        \n",
    "        epoch_sec: time interval for one segment of mashes (0.0625 is 1/16 as a fraction)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Event codes mean different actions for two groups of runs\n",
    "    # run_type_0 = '01'.split(',')\n",
    "    # run_type_1 = '03,07,11'.split(',')\n",
    "    # run_type_2 = '05,09,13'.split(',')\n",
    "    \n",
    "    run_type_0 = '02'.split(',')\n",
    "    run_type_1 = '04,08,12'.split(',')\n",
    "    run_type_2 = '06,10,14'.split(',')\n",
    "    \n",
    "    # Initiate X, y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # To compute the completion rate\n",
    "    count = len(subj_num)\n",
    "    \n",
    "    # fixed numbers\n",
    "    nChan = 64 \n",
    "    sfreq = 160\n",
    "    sliding = epoch_sec/2 \n",
    "    timeFromQue = 0.5\n",
    "    timeExercise = 4.1 #secomds\n",
    "\n",
    "    # Sub-function to assign X and X, y\n",
    "    def append_X(n_segments, data, event=[]):\n",
    "        # Data should be changed\n",
    "        '''This function generate a tensor for X and append it to the existing X'''\n",
    "    \n",
    "        def window(n):\n",
    "            # (80) + (160 * 1/16 * n) \n",
    "            windowStart = int(timeFromQue*sfreq) + int(sfreq*sliding*n) \n",
    "            # (80) + (160 * 1/16 * (n+2))\n",
    "            windowEnd = int(timeFromQue*sfreq) + int(sfreq*sliding*(n+2)) \n",
    "            \n",
    "            while (windowEnd - windowStart) != sfreq*epoch_sec:\n",
    "                windowEnd += int(sfreq*epoch_sec) - (windowEnd - windowStart)\n",
    "                \n",
    "            return [windowStart, windowEnd]\n",
    "        \n",
    "        new_x = []\n",
    "        for n in range(n_segments):\n",
    "            # print('data[:, ',window(n)[0],':',window(n)[1],'].shape = ', data[:, window(n)[0]:window(n)[1]].shape, '(',nChan,',',int(sfreq*epoch_sec),')')\n",
    "            \n",
    "            if data[:, window(n)[0]:window(n)[1]].shape==(nChan, int(sfreq*epoch_sec)):\n",
    "                new_x.append(data[:, window(n)[0]: window(n)[1]])\n",
    "                 \n",
    "        return new_x\n",
    "    \n",
    "    def append_X_Y(run_type, event, old_x, old_y, data):\n",
    "        '''This function seperate the type of events \n",
    "        (refer to the data descriptitons for the list of the types)\n",
    "        Then assign X and Y according to the event types'''\n",
    "        # Number of sliding windows\n",
    "\n",
    "        # print('data', data.shape[1])\n",
    "        n_segments = floor(data.shape[1]/(epoch_sec*sfreq*timeFromQue) - 1/epoch_sec - 1)\n",
    "        # print('run_'+str(run_type),' n_segments', n_segments)\n",
    "        \n",
    "        \n",
    "        # Rest excluded\n",
    "        if event[2] == emb['T0']:\n",
    "            return old_x, old_y\n",
    "        \n",
    "        # y assignment\n",
    "        if run_type == 1:\n",
    "            temp_y = [1] if event[2] == 'T1' else [2]\n",
    "        \n",
    "        elif run_type == 2:\n",
    "            temp_y = [3] if event[2] == 'T1' else [4]\n",
    "            \n",
    "        # print('timeExercise * sfreq', timeExercise*sfreq, ' ?= 656')\n",
    "        new_x = append_X(n_segments, data, event)\n",
    "        new_y = old_y + temp_y*len(new_x)\n",
    "        \n",
    "        return old_x + new_x, new_y\n",
    "    \n",
    "    # Iterate over subj_num: S001, S002, S003, ...\n",
    "    for i, subj in enumerate(subj_num):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Return completion rate\n",
    "        if i%((len(subj_num)//10)+1) == 0:\n",
    "            print('\\n')\n",
    "            print('working on {}, {:.0%} completed'.format(subj, i/count))\n",
    "            print('\\n')\n",
    "        \n",
    "        old_size = np.array(y).shape[0]\n",
    "        # print('subj:', subj, '| y.shape', np.array(y).shape ,'| X.shape', np.array(X).shape)\n",
    "\n",
    "        # Get file names\n",
    "        fnames = glob(os.path.join(PATH, subj, subj+'R*.edf'))\n",
    "        # Hold only the files that have an even number\n",
    "        fnames = sorted([name for name in fnames if name[-6:-4] in run_type_0+run_type_1+run_type_2])\n",
    "\n",
    "        # for each of ['02', '04', '06', '08', '12', '14']\n",
    "        for i, fname in enumerate(fnames):\n",
    "            \n",
    "            # Import data into MNE raw object\n",
    "            raw = read_raw_edf(fname, preload=True, verbose=False)\n",
    "            \n",
    "            picks = pick_types(raw.info, eeg=True)\n",
    "            # print('n_times', raw.n_times)\n",
    "            \n",
    "            if raw.info['sfreq'] != 160:\n",
    "                print('{} is sampled at 128Hz so will be excluded.'.format(subj))\n",
    "                break\n",
    "            \n",
    "            \n",
    "            # High-pass filtering\n",
    "            raw.filter(l_freq=1, h_freq=None, picks=picks)\n",
    "\n",
    "            # Get annotation\n",
    "            try:\n",
    "                events = events_from_annotations(raw, verbose=False)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # Get data\n",
    "            data = raw.get_data(picks=picks)\n",
    "\n",
    "            # print('event.shape', np.array(events[0]).shape, '| data.shape', data.shape)\n",
    "\n",
    "            # Number of this run\n",
    "            which_run = fname[-6:-4]\n",
    "\n",
    "            \"\"\" Assignment Starts \"\"\" \n",
    "            # run 1 - baseline (eye closed)\n",
    "            if which_run in run_type_0:\n",
    "\n",
    "                # Number of sliding windows\n",
    "                n_segments = floor(data.shape[1]/(epoch_sec*sfreq*timeFromQue) - 1/epoch_sec - 1)\n",
    "                # print('run_0 n_segments', n_segments)\n",
    "\n",
    "                # Append 0`s based on number of windows\n",
    "                new_X = append_X(n_segments, data)\n",
    "                X += new_X\n",
    "                y.extend([0] * len(new_X))\n",
    "                # print(events[0])   \n",
    "\n",
    "            # run 4,8,12 - imagine opening and closing left or right fist    \n",
    "            elif which_run in run_type_1:\n",
    "\n",
    "                for i, event in enumerate(events[0]):\n",
    "\n",
    "                    X, y = append_X_Y(run_type=1, event=event, old_x=X, old_y=y, data=data[:, int(event[0]) : int(event[0] + timeExercise*sfreq)])\n",
    "                    # print(event)   \n",
    "\n",
    "            # run 6,10,14 - imagine opening and closing both fists or both feet\n",
    "            elif which_run in run_type_2:\n",
    "\n",
    "                for i, event in enumerate(events[0]):      \n",
    "\n",
    "                    X, y = append_X_Y(run_type=2, event=event, old_x=X, old_y=y, data=data[:, int(event[0]) : int(event[0] + timeExercise*sfreq)])\n",
    "                    # print(event)    \n",
    "\n",
    "        print('subj:', subj, '|', np.array(y).shape[0] - old_size, '| y.shape', np.array(y).shape ,'| X.shape', np.array(X).shape)\n",
    "        \n",
    "    print(np.array(X).shape)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "working on S001, 0% completed\n",
      "\n",
      "\n",
      "subj: S001 | 12195 | y.shape (12195,) | X.shape (12195, 64, 10)\n",
      "subj: S002 | 12195 | y.shape (24390,) | X.shape (24390, 64, 10)\n",
      "subj: S003 | 12195 | y.shape (36585,) | X.shape (36585, 64, 10)\n",
      "subj: S004 | 12195 | y.shape (48780,) | X.shape (48780, 64, 10)\n",
      "subj: S005 | 12195 | y.shape (60975,) | X.shape (60975, 64, 10)\n",
      "subj: S006 | 12195 | y.shape (73170,) | X.shape (73170, 64, 10)\n",
      "subj: S007 | 12195 | y.shape (85365,) | X.shape (85365, 64, 10)\n",
      "subj: S008 | 12195 | y.shape (97560,) | X.shape (97560, 64, 10)\n",
      "subj: S009 | 12195 | y.shape (109755,) | X.shape (109755, 64, 10)\n",
      "subj: S010 | 12195 | y.shape (121950,) | X.shape (121950, 64, 10)\n",
      "subj: S011 | 12195 | y.shape (134145,) | X.shape (134145, 64, 10)\n",
      "\n",
      "\n",
      "working on S012, 10% completed\n",
      "\n",
      "\n",
      "subj: S012 | 12195 | y.shape (146340,) | X.shape (146340, 64, 10)\n",
      "subj: S013 | 12195 | y.shape (158535,) | X.shape (158535, 64, 10)\n",
      "subj: S014 | 12195 | y.shape (170730,) | X.shape (170730, 64, 10)\n",
      "subj: S015 | 12195 | y.shape (182925,) | X.shape (182925, 64, 10)\n",
      "subj: S016 | 12195 | y.shape (195120,) | X.shape (195120, 64, 10)\n",
      "subj: S017 | 12195 | y.shape (207315,) | X.shape (207315, 64, 10)\n",
      "subj: S018 | 12195 | y.shape (219510,) | X.shape (219510, 64, 10)\n",
      "subj: S019 | 12195 | y.shape (231705,) | X.shape (231705, 64, 10)\n",
      "subj: S020 | 12195 | y.shape (243900,) | X.shape (243900, 64, 10)\n",
      "subj: S021 | 12195 | y.shape (256095,) | X.shape (256095, 64, 10)\n",
      "subj: S022 | 12195 | y.shape (268290,) | X.shape (268290, 64, 10)\n",
      "\n",
      "\n",
      "working on S023, 21% completed\n",
      "\n",
      "\n",
      "subj: S023 | 12195 | y.shape (280485,) | X.shape (280485, 64, 10)\n",
      "subj: S024 | 12195 | y.shape (292680,) | X.shape (292680, 64, 10)\n",
      "subj: S025 | 12195 | y.shape (304875,) | X.shape (304875, 64, 10)\n",
      "subj: S026 | 12195 | y.shape (317070,) | X.shape (317070, 64, 10)\n",
      "subj: S027 | 12195 | y.shape (329265,) | X.shape (329265, 64, 10)\n",
      "subj: S028 | 12195 | y.shape (341460,) | X.shape (341460, 64, 10)\n",
      "subj: S029 | 12195 | y.shape (353655,) | X.shape (353655, 64, 10)\n",
      "subj: S030 | 12195 | y.shape (365850,) | X.shape (365850, 64, 10)\n",
      "subj: S031 | 12195 | y.shape (378045,) | X.shape (378045, 64, 10)\n",
      "subj: S032 | 12195 | y.shape (390240,) | X.shape (390240, 64, 10)\n",
      "subj: S033 | 12195 | y.shape (402435,) | X.shape (402435, 64, 10)\n",
      "\n",
      "\n",
      "working on S034, 31% completed\n",
      "\n",
      "\n",
      "subj: S034 | 12180 | y.shape (414615,) | X.shape (414615, 64, 10)\n",
      "subj: S035 | 12195 | y.shape (426810,) | X.shape (426810, 64, 10)\n",
      "subj: S036 | 12195 | y.shape (439005,) | X.shape (439005, 64, 10)\n",
      "subj: S037 | 12180 | y.shape (451185,) | X.shape (451185, 64, 10)\n",
      "subj: S038 | 12195 | y.shape (463380,) | X.shape (463380, 64, 10)\n",
      "subj: S039 | 12195 | y.shape (475575,) | X.shape (475575, 64, 10)\n",
      "subj: S040 | 12195 | y.shape (487770,) | X.shape (487770, 64, 10)\n",
      "subj: S041 | 12189 | y.shape (499959,) | X.shape (499959, 64, 10)\n",
      "subj: S042 | 12195 | y.shape (512154,) | X.shape (512154, 64, 10)\n",
      "subj: S043 | 12195 | y.shape (524349,) | X.shape (524349, 64, 10)\n",
      "subj: S044 | 12195 | y.shape (536544,) | X.shape (536544, 64, 10)\n",
      "\n",
      "\n",
      "working on S045, 42% completed\n",
      "\n",
      "\n",
      "subj: S045 | 12195 | y.shape (548739,) | X.shape (548739, 64, 10)\n",
      "subj: S046 | 12195 | y.shape (560934,) | X.shape (560934, 64, 10)\n",
      "subj: S047 | 12195 | y.shape (573129,) | X.shape (573129, 64, 10)\n",
      "subj: S048 | 12195 | y.shape (585324,) | X.shape (585324, 64, 10)\n",
      "subj: S049 | 12195 | y.shape (597519,) | X.shape (597519, 64, 10)\n",
      "subj: S050 | 12195 | y.shape (609714,) | X.shape (609714, 64, 10)\n",
      "subj: S051 | 12195 | y.shape (621909,) | X.shape (621909, 64, 10)\n",
      "subj: S052 | 12195 | y.shape (634104,) | X.shape (634104, 64, 10)\n",
      "subj: S053 | 12195 | y.shape (646299,) | X.shape (646299, 64, 10)\n",
      "subj: S054 | 12195 | y.shape (658494,) | X.shape (658494, 64, 10)\n",
      "subj: S055 | 12195 | y.shape (670689,) | X.shape (670689, 64, 10)\n",
      "\n",
      "\n",
      "working on S056, 52% completed\n",
      "\n",
      "\n",
      "subj: S056 | 12195 | y.shape (682884,) | X.shape (682884, 64, 10)\n",
      "subj: S057 | 12195 | y.shape (695079,) | X.shape (695079, 64, 10)\n",
      "subj: S058 | 12195 | y.shape (707274,) | X.shape (707274, 64, 10)\n",
      "subj: S059 | 12195 | y.shape (719469,) | X.shape (719469, 64, 10)\n",
      "subj: S060 | 12195 | y.shape (731664,) | X.shape (731664, 64, 10)\n",
      "subj: S061 | 12195 | y.shape (743859,) | X.shape (743859, 64, 10)\n",
      "subj: S062 | 12195 | y.shape (756054,) | X.shape (756054, 64, 10)\n",
      "subj: S063 | 12195 | y.shape (768249,) | X.shape (768249, 64, 10)\n",
      "subj: S064 | 12186 | y.shape (780435,) | X.shape (780435, 64, 10)\n",
      "subj: S065 | 12195 | y.shape (792630,) | X.shape (792630, 64, 10)\n",
      "subj: S066 | 12195 | y.shape (804825,) | X.shape (804825, 64, 10)\n",
      "\n",
      "\n",
      "working on S067, 63% completed\n",
      "\n",
      "\n",
      "subj: S067 | 12195 | y.shape (817020,) | X.shape (817020, 64, 10)\n",
      "subj: S068 | 12195 | y.shape (829215,) | X.shape (829215, 64, 10)\n",
      "subj: S069 | 12195 | y.shape (841410,) | X.shape (841410, 64, 10)\n",
      "subj: S070 | 12195 | y.shape (853605,) | X.shape (853605, 64, 10)\n",
      "subj: S071 | 12195 | y.shape (865800,) | X.shape (865800, 64, 10)\n",
      "subj: S072 | 12180 | y.shape (877980,) | X.shape (877980, 64, 10)\n",
      "subj: S073 | 12177 | y.shape (890157,) | X.shape (890157, 64, 10)\n",
      "subj: S074 | 12180 | y.shape (902337,) | X.shape (902337, 64, 10)\n",
      "subj: S075 | 12195 | y.shape (914532,) | X.shape (914532, 64, 10)\n",
      "subj: S076 | 12177 | y.shape (926709,) | X.shape (926709, 64, 10)\n",
      "subj: S077 | 12195 | y.shape (938904,) | X.shape (938904, 64, 10)\n",
      "\n",
      "\n",
      "working on S078, 73% completed\n",
      "\n",
      "\n",
      "subj: S078 | 12195 | y.shape (951099,) | X.shape (951099, 64, 10)\n",
      "subj: S079 | 12195 | y.shape (963294,) | X.shape (963294, 64, 10)\n",
      "subj: S080 | 12195 | y.shape (975489,) | X.shape (975489, 64, 10)\n",
      "subj: S081 | 12195 | y.shape (987684,) | X.shape (987684, 64, 10)\n",
      "subj: S082 | 12195 | y.shape (999879,) | X.shape (999879, 64, 10)\n",
      "subj: S083 | 12195 | y.shape (1012074,) | X.shape (1012074, 64, 10)\n",
      "subj: S084 | 12195 | y.shape (1024269,) | X.shape (1024269, 64, 10)\n",
      "subj: S085 | 12195 | y.shape (1036464,) | X.shape (1036464, 64, 10)\n",
      "subj: S086 | 12195 | y.shape (1048659,) | X.shape (1048659, 64, 10)\n",
      "subj: S087 | 12195 | y.shape (1060854,) | X.shape (1060854, 64, 10)\n",
      "subj: S090 | 12195 | y.shape (1073049,) | X.shape (1073049, 64, 10)\n",
      "\n",
      "\n",
      "working on S091, 84% completed\n",
      "\n",
      "\n",
      "subj: S091 | 12195 | y.shape (1085244,) | X.shape (1085244, 64, 10)\n",
      "subj: S093 | 12195 | y.shape (1097439,) | X.shape (1097439, 64, 10)\n",
      "subj: S094 | 12195 | y.shape (1109634,) | X.shape (1109634, 64, 10)\n",
      "subj: S095 | 12195 | y.shape (1121829,) | X.shape (1121829, 64, 10)\n",
      "subj: S096 | 12195 | y.shape (1134024,) | X.shape (1134024, 64, 10)\n",
      "subj: S097 | 12163 | y.shape (1146187,) | X.shape (1146187, 64, 10)\n",
      "subj: S098 | 12195 | y.shape (1158382,) | X.shape (1158382, 64, 10)\n",
      "subj: S099 | 12195 | y.shape (1170577,) | X.shape (1170577, 64, 10)\n",
      "subj: S101 | 12195 | y.shape (1182772,) | X.shape (1182772, 64, 10)\n",
      "subj: S102 | 12180 | y.shape (1194952,) | X.shape (1194952, 64, 10)\n",
      "subj: S103 | 12195 | y.shape (1207147,) | X.shape (1207147, 64, 10)\n",
      "\n",
      "\n",
      "working on S104, 94% completed\n",
      "\n",
      "\n",
      "subj: S104 | 11948 | y.shape (1219095,) | X.shape (1219095, 64, 10)\n",
      "subj: S105 | 12195 | y.shape (1231290,) | X.shape (1231290, 64, 10)\n",
      "subj: S106 | 12195 | y.shape (1243485,) | X.shape (1243485, 64, 10)\n",
      "subj: S107 | 12195 | y.shape (1255680,) | X.shape (1255680, 64, 10)\n",
      "subj: S108 | 12195 | y.shape (1267875,) | X.shape (1267875, 64, 10)\n",
      "subj: S109 | 12195 | y.shape (1280070,) | X.shape (1280070, 64, 10)\n",
      "(1280070, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(FNAMES, epoch_sec=0.0625) # to get 20 set 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280070, 64, 10)\n",
      "(1280070, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.getsizeof(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( X , open( \"./py/stack/X.p\", \"wb\" ) , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( y , open( \"./py/stack/y.p\", \"wb\" ) , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load( open( \"./py/stack/X.p\", \"rb\" ) )\n",
    "y = pickle.load( open( \"./py/stack/y.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "The original goal of applying neural networks is to exclude hand-crafted algorithms & preprocessing as much as possible. I did not use any proprecessing techniques further than standardization to build an end-to-end classifer from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, scale\n",
    "\n",
    "#%%\n",
    "def convert_mesh(X):\n",
    "    \n",
    "    mesh = np.zeros((X.shape[0], X.shape[2], 10, 11, 1))\n",
    "    X = np.swapaxes(X, 1, 2)\n",
    "    \n",
    "    # 1st line\n",
    "    mesh[:, :, 0, 4:7, 0] = X[:,:,21:24]; print('1st finished')\n",
    "    \n",
    "    # 2nd line\n",
    "    mesh[:, :, 1, 3:8, 0] = X[:,:,24:29]; print('2nd finished')\n",
    "    \n",
    "    # 3rd line\n",
    "    mesh[:, :, 2, 1:10, 0] = X[:,:,29:38]; print('3rd finished')\n",
    "    \n",
    "    # 4th line\n",
    "    mesh[:, :, 3, 1:10, 0] = np.concatenate((X[:,:,38].reshape(-1, X.shape[1], 1),\\\n",
    "                                          X[:,:,0:7], X[:,:,39].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('4th finished')\n",
    "    \n",
    "    # 5th line\n",
    "    mesh[:, :, 4, 0:11, 0] = np.concatenate((X[:,:,(42, 40)],\\\n",
    "                                        X[:,:,7:14], X[:,:,(41, 43)]), axis=2)\n",
    "    print('5th finished')\n",
    "    \n",
    "    # 6th line\n",
    "    mesh[:, :, 5, 1:10, 0] = np.concatenate((X[:,:,44].reshape(-1, X.shape[1], 1),\\\n",
    "                                        X[:,:,14:21], X[:,:,45].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('6th finished')\n",
    "               \n",
    "    # 7th line\n",
    "    mesh[:, :, 6, 1:10, 0] = X[:,:,46:55]; print('7th finished')\n",
    "    \n",
    "    # 8th line\n",
    "    mesh[:, :, 7, 3:8, 0] = X[:,:,55:60]; print('8th finished')\n",
    "    \n",
    "    # 9th line\n",
    "    mesh[:, :, 8, 4:7, 0] = X[:,:,60:63]; print('9th finished')\n",
    "    \n",
    "    # 10th line\n",
    "    mesh[:, :, 9, 5, 0] = X[:,:,63]; print('10th finished')\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "#%%\n",
    "def prepare_data(X, y, test_ratio=0.2, return_mesh=True, set_seed=42):\n",
    "    \n",
    "    # y encoding\n",
    "    oh = OneHotEncoder(categories='auto')\n",
    "    y = oh.fit_transform(y).toarray()\n",
    "    \n",
    "    # Shuffle trials\n",
    "    np.random.seed(set_seed)\n",
    "    trials = X.shape[0]\n",
    "    shuffle_indices = np.random.permutation(trials)\n",
    "    X = X[shuffle_indices]\n",
    "    y = y[shuffle_indices]\n",
    "    \n",
    "    # Test set seperation\n",
    "    train_size = int(trials*(1-test_ratio)) \n",
    "    X_train, X_test, y_train, y_test = X[:train_size,:,:], X[train_size:,:,:],\\\n",
    "                                    y[:train_size,:], y[train_size:,:]\n",
    "                                    \n",
    "    # Z-score Normalization\n",
    "    def scale_data(X):\n",
    "        shape = X.shape\n",
    "        for i in range(shape[0]):\n",
    "            # Standardize a dataset along any axis\n",
    "            # Center to the mean and component wise scale to unit variance.\n",
    "            X[i,:, :] = scale(X[i,:, :])\n",
    "            if i%int(shape[0]//10) == 0:\n",
    "                print('{:.0%} done'.format((i+1)/shape[0]))   \n",
    "        return X\n",
    "            \n",
    "    X_train, X_test  = scale_data(X_train), scale_data(X_test)\n",
    "    if return_mesh:\n",
    "        X_train, X_test = convert_mesh(X_train), convert_mesh(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "10% done\n",
      "20% done\n",
      "30% done\n",
      "40% done\n",
      "50% done\n",
      "60% done\n",
      "70% done\n",
      "80% done\n",
      "90% done\n",
      "100% done\n",
      "0% done\n",
      "10% done\n",
      "20% done\n",
      "30% done\n",
      "40% done\n",
      "50% done\n",
      "60% done\n",
      "70% done\n",
      "80% done\n",
      "90% done\n",
      "100% done\n",
      "1st finished\n",
      "2nd finished\n",
      "3rd finished\n",
      "4th finished\n",
      "5th finished\n",
      "6th finished\n",
      "7th finished\n",
      "8th finished\n",
      "9th finished\n",
      "10th finished\n",
      "1st finished\n",
      "2nd finished\n",
      "3rd finished\n",
      "4th finished\n",
      "5th finished\n",
      "6th finished\n",
      "7th finished\n",
      "8th finished\n",
      "9th finished\n",
      "10th finished\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( [X_train, y_train]  , open( \"./py/stack/train.p\", \"wb\" ) , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( [X_test, y_test]  , open( \"./py/stack/test.p\", \"wb\" ) , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, y_train] = pickle.load( open( \"./py/stack/train.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_test, y_test] = pickle.load( open( \"./py/stack/test.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the EEG recording instrument has 3D locations over the subjects\\` scalp, it is essential for the model to learn from the spatial pattern as well as the temporal pattern. I transformed the data into 2D meshes that represents the locations of the electrodes so that stacked convolutional neural networks can grasp the spatial information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling - Time-Distributed CNN + RNN\n",
    "\n",
    "Training Plan:\n",
    "\n",
    "+ 4 GPU units (Nvidia Tesla P100) were used to train this neural network.\n",
    "+ Instead of training the whole model at once, I trained the first block (CNN) first. Then using the trained parameters as initial values, I trained the next blocks step-by-step. This approach can greatly reduce the time required for training and help avoiding falling into local minimums.\n",
    "+ The first blocks (CNN) can be applied for other EEG classification models as a pre-trained base.\n",
    "\n",
    "+ The initial learning rate is set to be $10^{3}$ with Adam optimization. I used several callbacks such as ReduceLROnPlateau which adjusts the learning rate at local minima. Also, I record the log for tensorboard to monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024056, 10, 10, 11, 1)\n",
      "(256014, 10, 10, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.squeeze().reshape(*X_train.squeeze().shape, 1)\n",
    "X_test = X_test.squeeze().reshape(*X_test.squeeze().shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024056, 10, 10, 11, 1)\n",
      "(256014, 10, 10, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another dimension, 1, to apply CNN for each time frame.\n",
    "X_train = X_train.reshape(*X_train.shape, 1)\n",
    "X_test = X_test.reshape(*X_test.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024056, 10, 10, 11, 1)\n",
      "(256014, 10, 10, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Keras Implementation\n",
    "\n",
    "The Keras functional API is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 10, 11, 1)     0         \n",
      "_________________________________________________________________\n",
      "CNN1 (TimeDistributed)       (None, 10, 10, 11, 32)    320       \n",
      "_________________________________________________________________\n",
      "batch1 (BatchNormalization)  (None, 10, 10, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 10, 10, 11, 32)    0         \n",
      "_________________________________________________________________\n",
      "CNN2 (TimeDistributed)       (None, 10, 10, 11, 64)    18496     \n",
      "_________________________________________________________________\n",
      "batch2 (BatchNormalization)  (None, 10, 10, 11, 64)    256       \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 10, 10, 11, 64)    0         \n",
      "_________________________________________________________________\n",
      "CNN3 (TimeDistributed)       (None, 10, 10, 11, 128)   73856     \n",
      "_________________________________________________________________\n",
      "batch3 (BatchNormalization)  (None, 10, 10, 11, 128)   512       \n",
      "_________________________________________________________________\n",
      "act3 (Activation)            (None, 10, 10, 11, 128)   0         \n",
      "_________________________________________________________________\n",
      "flatten (TimeDistributed)    (None, 10, 14080)         0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   (None, 10, 1024)          14418944  \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "batch4 (BatchNormalization)  (None, 10, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 10, 64)            278784    \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 14,898,051\n",
      "Trainable params: 14,895,555\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Complicated Model - the same as Zhang`s\n",
    "input_shape = (10, 10, 11, 1)\n",
    "lecun = initializers.lecun_normal(seed=42)\n",
    "\n",
    "# TimeDistributed Wrapper\n",
    "def timeDist(layer, prev_layer, name):\n",
    "    return TimeDistributed(layer, name=name)(prev_layer)\n",
    "    \n",
    "# Input layer\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Convolutional layers block\n",
    "x = timeDist(Conv2D(32, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), inputs, name='CNN1')\n",
    "x = BatchNormalization(name='batch1')(x)\n",
    "x = Activation('elu', name='act1')(x)\n",
    "x = timeDist(Conv2D(64, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN2')\n",
    "x = BatchNormalization(name='batch2')(x)\n",
    "x = Activation('elu', name='act2')(x)\n",
    "x = timeDist(Conv2D(128, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN3')\n",
    "x = BatchNormalization(name='batch3')(x)\n",
    "x = Activation('elu', name='act3')(x)\n",
    "x = timeDist(Flatten(), x, name='flatten')\n",
    "\n",
    "# Fully connected layer block\n",
    "y = Dense(1024, kernel_initializer=lecun, name='FC')(x)\n",
    "y = Dropout(0.5, name='dropout1')(y)\n",
    "y = BatchNormalization(name='batch4')(y)\n",
    "y = Activation(activation='elu')(y)\n",
    "\n",
    "# Recurrent layers block\n",
    "z = LSTM(64, kernel_initializer=lecun, return_sequences=True, name='LSTM1')(y)\n",
    "z = LSTM(64, kernel_initializer=lecun, name='LSTM2')(z)\n",
    "\n",
    "# Fully connected layer block\n",
    "h = Dense(1024, kernel_initializer=lecun, activation='elu', name='FC2')(z)\n",
    "h = Dropout(0.5, name='dropout2')(h)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(3, activation='softmax')(h)\n",
    "\n",
    "# Model compile\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./py/model/model_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./py/model/model_14_0.7098.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "# Load a model to transfer pre-trained parameters\n",
    "trans_model = model.load('CNN_3blocks.h5')\n",
    "\n",
    "# Transfer learning - parameter copy & paste\n",
    "which_layer = 'CNN1,CNN2,CNN3,batch1,batch2,batch3'.split(',')\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "trans_layer_names = [layer.name for layer in trans_model.layers]\n",
    "\n",
    "for layer in which_layer:\n",
    "    ind = layer_names.index(layer)\n",
    "    trans_ind = trans_layer_names.index(layer)\n",
    "    model.layers[ind].set_weights(trans_model.layers[trans_ind].get_weights())\n",
    "    \n",
    "for layer in model.layers[:9]: # Freeze the first 9 layers(CNN block)\n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "\n",
    "# Turn on multi-GPU mode\n",
    "model = multi_gpu_model(model, gpus=4)\n",
    "\n",
    "This metrics calculate sensitivity and specificity batch-wise.\n",
    "Keras development team removed this feature because\n",
    "these metrics should be understood as global metrics.\n",
    "\n",
    "\n",
    "I am not using it this time.\n",
    "\n",
    "# Metrics - sensitivity, specificity, accuracy\n",
    "def sens(y_true, y_pred): # Sensitivity\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def prec(y_true, y_pred): # Precision\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class CustomModelCheckPoint(Callback):\n",
    "    def __init__(self,**kargs):\n",
    "        super(CustomModelCheckPoint,self).__init__(**kargs)\n",
    "        self.epoch_accuracy = {} # loss at given epoch\n",
    "        self.epoch_loss = {} # accuracy at given epoch\n",
    "        def on_epoch_begin(self,epoch, logs={}):\n",
    "            # Things done on beginning of epoch. \n",
    "            return\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            # things done on end of the epoch\n",
    "            self.epoch_accuracy[epoch] = logs.get(\"acc\")\n",
    "            self.epoch_loss[epoch] = logs.get(\"loss\")\n",
    "            self.model.save_weights(\"./py/model/model_%d.h5\" %epoch) # save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValTensorBoard(TensorBoard):\n",
    "    '''\n",
    "    Plot training and validation losses on the same Tensorboard graph\n",
    "    Supersede Tensorboard callback\n",
    "    '''\n",
    "    def __init__(self, log_dir=\"./py/logs/\", **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [callbacks.ModelCheckpoint(\"./py/weights/weights_{epoch:02d}_{val_acc:.4f}.h5\", save_best_only=False, monitor='val_loss'),\n",
    "                 callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "                 callbacks.CSVLogger(\"./py/logs/log.csv\", separator=',', append=True),\n",
    "                 TrainValTensorBoard()]\n",
    "\n",
    "# Start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 819244 samples, validate on 204812 samples\n",
      "Epoch 1/500\n",
      "819244/819244 [==============================] - 1857s 2ms/step - loss: 0.8649 - acc: 0.5072 - val_loss: 0.8132 - val_acc: 0.5534\n",
      "Epoch 2/500\n",
      "819244/819244 [==============================] - 1845s 2ms/step - loss: 0.7711 - acc: 0.5772 - val_loss: 0.7690 - val_acc: 0.5929\n",
      "Epoch 3/500\n",
      "819244/819244 [==============================] - 1694s 2ms/step - loss: 0.7138 - acc: 0.6174 - val_loss: 0.7605 - val_acc: 0.6134\n",
      "Epoch 4/500\n",
      "819244/819244 [==============================] - 1371s 2ms/step - loss: 0.6739 - acc: 0.6431 - val_loss: 0.7312 - val_acc: 0.6324\n",
      "Epoch 5/500\n",
      "819244/819244 [==============================] - 1372s 2ms/step - loss: 0.6411 - acc: 0.6650 - val_loss: 0.7174 - val_acc: 0.6452\n",
      "Epoch 6/500\n",
      "819244/819244 [==============================] - 1372s 2ms/step - loss: 0.6138 - acc: 0.6822 - val_loss: 0.7320 - val_acc: 0.6507\n",
      "Epoch 7/500\n",
      "819244/819244 [==============================] - 1372s 2ms/step - loss: 0.5896 - acc: 0.6983 - val_loss: 0.7156 - val_acc: 0.6661\n",
      "Epoch 8/500\n",
      "819244/819244 [==============================] - 1793s 2ms/step - loss: 0.5672 - acc: 0.7124 - val_loss: 0.7323 - val_acc: 0.6673\n",
      "Epoch 9/500\n",
      "819244/819244 [==============================] - 1859s 2ms/step - loss: 0.5468 - acc: 0.7256 - val_loss: 0.7328 - val_acc: 0.6774\n",
      "Epoch 10/500\n",
      "819244/819244 [==============================] - 1876s 2ms/step - loss: 0.5273 - acc: 0.7376 - val_loss: 0.7079 - val_acc: 0.6859\n",
      "Epoch 11/500\n",
      "819244/819244 [==============================] - 1680s 2ms/step - loss: 0.5095 - acc: 0.7487 - val_loss: 0.7181 - val_acc: 0.6902\n",
      "Epoch 12/500\n",
      "819244/819244 [==============================] - 1681s 2ms/step - loss: 0.4920 - acc: 0.7594 - val_loss: 0.7240 - val_acc: 0.6918\n",
      "Epoch 13/500\n",
      "819244/819244 [==============================] - 1701s 2ms/step - loss: 0.4757 - acc: 0.7689 - val_loss: 0.7113 - val_acc: 0.7011\n",
      "Epoch 14/500\n",
      "819244/819244 [==============================] - 1699s 2ms/step - loss: 0.4608 - acc: 0.7779 - val_loss: 0.7229 - val_acc: 0.7060\n",
      "Epoch 15/500\n",
      "212608/819244 [======>.......................] - ETA: 19:34 - loss: 0.4393 - acc: 0.7903"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=500, shuffle=True, \n",
    "                    validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "history = model.fit(X_train[:1000], y_train[:1000], batch_size=1, epochs=1, shuffle=True, \n",
    "                    validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tensorflow Eager Execution API\n",
    "\n",
    "TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = X.shape[0] # PhysioNet data input (mesh shape: 10*11)\n",
    "num_classes = 5 # PhysioNet total classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF Dataset to split data into batches\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "dataset_iter = tfe.Iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhangModel(tf.keras.Model):\n",
    "    def __init__(self, n_nodes=[3,2,2], \n",
    "                 initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")):\n",
    "        \"\"\"\n",
    "        This is a tensorflow implementation of Zhang`s model (2018) with \n",
    "        3 CNN, 2 LSTM, 2 dense layers by default.\n",
    "        \n",
    "        n_nodes [list] : specifies the number of layers for each block. \n",
    "                        [CNN, LSTM, DENSE] respectively.\n",
    "        initializer [tf.layers] : defualt initializer set to be He initializer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_CNN, self.n_LSTM, self.n_dense = n_nodes\n",
    "        self.CNN, self.LSTM, self.dense = [[] for i in range(len(n_nodes))]\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        count = 0\n",
    "        for n in range(self.n_CNN):\n",
    "            count += 1\n",
    "            n_filter = 32*2**count\n",
    "            \n",
    "            self.CNN.append(tf.keras.layers.Conv2D(n_filter, (3, 3), padding='same', \n",
    "                                                data_format='channels_last',\n",
    "                                                kernel_initializer=self.initializer))\n",
    "        \n",
    "        for n in range(self.n_LSTM):    \n",
    "            n_hidden = 64\n",
    "            return_sequences = False if n == self.n_LSTM-1 else True\n",
    "            \n",
    "            name = 'LSTM' + str(len(self.LSTM)+1)            \n",
    "            self.LSTM.append(tf.keras.layers.LSTM(n_hidden, kernel_initializer=self.initializer, \n",
    "                                             return_sequences=return_sequences, name=name))\n",
    "            \n",
    "        for n in range(self.n_dense):\n",
    "            n_node=1024\n",
    "            \n",
    "            name = 'Dense' + str(len(self.dense)+1)\n",
    "            self.dense.append(tf.keras.layers.Dense(n_node, \n",
    "                                                    kernel_initializer=self.initializer, name=name))\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        \"Run the model.\"\n",
    "        \n",
    "        assert self.CNN, 'No CNN blocks defined!'\n",
    "        assert self.dense, 'No Dense Blocks defined!'\n",
    "        assert self.LSTM, 'No LSTM blocks defined!'\n",
    "        \n",
    "        def timeDist(layer, prev_layer, name):\n",
    "            return tf.keras.layers.TimeDistributed(layer, name=name)(prev_layer)\n",
    "        \n",
    "        for i, layer in enumerate(self.CNN):\n",
    "            name = 'CNN' + str(i+1)\n",
    "            nameBatch = 'batch' + str(i+1)\n",
    "            nameAct = 'act' + str(i+1)\n",
    "            \n",
    "            prev_layer = input_tensor if i==0 else x\n",
    "            \n",
    "            x = timeDist(layer, prev_layer, name=name)\n",
    "            x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "            x = tf.nn.elu(x, name=nameAct)\n",
    "            \n",
    "        x = timeDist(tf.keras.layers.Flatten(), x, name='flatten')\n",
    "        \n",
    "        for i, layer in enumerate(self.dense):            \n",
    "            \n",
    "            nameDrop = 'drop' + str(i+1)\n",
    "            nameBatch = 'batch' + str(i+1)\n",
    "            nameAct = 'act' + str(i+1)\n",
    "            \n",
    "            if i == len(self.dense)-1:\n",
    "                break\n",
    "            \n",
    "            x = layer(x)\n",
    "            x = tf.keras.layers.Dropout(0.5, name=nameDrop)(x)\n",
    "            x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "            x = tf.nn.elu(x, name=nameAct)\n",
    "            \n",
    "        for i, layer in enumerate(self.LSTM):\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.dense[-1](x)\n",
    "        x = tf.keras.layers.Dropout(0.5, name=nameDrop)(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "        x = tf.nn.elu(x, name=nameAct)\n",
    "        \n",
    "        output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ZhangModel([3, 2, 2])\n",
    "print(model(tf.random_normal([1, 10, 10, 11, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy loss function\n",
    "def loss_fn(inference_fn, inputs, labels):\n",
    "    # Using sparse_softmax cross entropy\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=inference_fn(inputs), labels=labels))\n",
    "\n",
    "# Calculate accuracy\n",
    "def accuracy_fn(inference_fn, inputs, labels):\n",
    "    prediction = inference_fn(inputs)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Compute gradients\n",
    "grad = tfe.implicit_gradients(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "average_loss = 0.\n",
    "average_acc = 0.\n",
    "for step in range(num_steps):\n",
    "\n",
    "    # Iterate through the dataset\n",
    "    try:\n",
    "        d = dataset_iter.next()\n",
    "    except StopIteration:\n",
    "        # Refill queue\n",
    "        dataset_iter = tfe.Iterator(dataset)\n",
    "        d = dataset_iter.next()\n",
    "\n",
    "    # EEGs\n",
    "    x_batch = d[0]\n",
    "    # Labels\n",
    "    y_batch = tf.cast(d[1], dtype=tf.int64)\n",
    "\n",
    "    # Compute the batch loss\n",
    "    batch_loss = loss_fn(model, x_batch, y_batch)\n",
    "    average_loss += batch_loss\n",
    "    \n",
    "    # Compute the batch accuracy\n",
    "    batch_accuracy = accuracy_fn(model, x_batch, y_batch)\n",
    "    average_acc += batch_accuracy\n",
    "\n",
    "    if step == 0:\n",
    "        # Display the initial cost, before optimizing\n",
    "        print(\"Initial loss= {:.9f}\".format(average_loss))\n",
    "\n",
    "    # Update the variables following gradients info\n",
    "    optimizer.apply_gradients(grad(model, x_batch, y_batch))\n",
    "\n",
    "    # Display info\n",
    "    if (step + 1) % display_step == 0 or step == 0:\n",
    "        if step > 0:\n",
    "            average_loss /= display_step\n",
    "            average_acc /= display_step\n",
    "        print(\"Step:\", '%04d' % (step + 1), \" loss=\",\n",
    "              \"{:.9f}\".format(average_loss), \" accuracy=\",\n",
    "              \"{:.4f}\".format(average_acc))\n",
    "        average_loss = 0.\n",
    "        average_acc = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in libraries\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories\n",
    "if not os.path.exists('./py/metrics/'):\n",
    "    os.makedirs('./py/metrics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history[loss_list[0]]) + 1)\n",
    "    \n",
    "   ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history[l], 'b', label='Training loss (' + str(str(format(history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history[l], 'g', label='Validation loss (' + str(str(format(history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./py/metrics/loss.png\")\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history[l], 'b', label='Training accuracy (' + str(format(history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history[l], 'g', label='Validation accuracy (' + str(format(history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(\"./py/metrics/acc.png\")\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(\"./py/metrics/confuMat.png\")\n",
    "    plt.show()\n",
    "    \n",
    "def full_multiclass_report(model,\n",
    "                           x,\n",
    "                           y_true,\n",
    "                           classes):\n",
    "    \n",
    "    # 2. Predict classes and stores in y_pred\n",
    "    y_pred = model.predict(x).argmax(axis=1)\n",
    "    \n",
    "    # 3. Print accuracy score\n",
    "    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # 4. Print classification report\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_true,y_pred,digits=4))    \n",
    "    \n",
    "    # 5. Plot confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "    print(cnf_matrix)\n",
    "    plot_confusion_matrix(cnf_matrix,classes=classes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "howManyTest = 0.2\n",
    "\n",
    "thisInd = np.random.randint(0, len(X_test), size=(len(X_test)//howManyTest))\n",
    "X_conf, y_conf = X_test[[i for i in thisInd], :], y_test[[i for i in thisInd],:] \n",
    "\n",
    "'''\n",
    "## Only if you have a previous model + history\n",
    "# Get the model\n",
    "model = models.load_model('./py/model/model_1230.h5')\n",
    "\n",
    "# Get the history\n",
    "with open('./history/history_1230.pkl', 'rb') as hist:\n",
    "    history = pickle.load(hist)\n",
    "'''\n",
    "\n",
    "# Get the graphics\n",
    "plot_history(history)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "full_multiclass_report(model,\n",
    "                       X_test,\n",
    "                       y_test.argmax(axis=1),\n",
    "                       [1,2,3,4,5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
